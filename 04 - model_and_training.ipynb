{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e38708-4880-4322-bab0-45074f430dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from typing import *\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch import nn, Tensor, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import datasets\n",
    "from datasets import *\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "import project_paths as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ebf580-7ec7-48bf-ab15-0cc838ecf95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(nn.Module):\n",
    "    '''A basic RNN cell that implements a single step of recurrent processing.\n",
    "    \n",
    "    The cell takes an input vector and previous hidden state, combines them through\n",
    "    linear transformations and a non-linear activation, and outputs the new hidden state.\n",
    "    \n",
    "    Args:\n",
    "        input_size (int): Size of the input vector\n",
    "        hidden_size (int): Size of the hidden state vector\n",
    "        \n",
    "    Attributes:\n",
    "        input_to_hidden (nn.Linear): Linear transformation from input to hidden state\n",
    "        hidden_to_hidden (nn.Linear): Linear transformation of previous hidden state\n",
    "        activation (nn.Tanh): Non-linear activation function\n",
    "    '''\n",
    "    def __init__(self, input_size: int, hidden_size: int) -> None:\n",
    "        super(RNNCell, self).__init__()\n",
    "\n",
    "        self.register_buffer('input_size', torch.tensor(input_size))\n",
    "        self.register_buffer('hidden_size', torch.tensor(hidden_size))\n",
    "        \n",
    "        self.input_to_hidden = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.hidden_to_hidden = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x: Tensor, h: Tensor) -> Tensor:\n",
    "        x = self.activation(self.input_to_hidden(x) + self.hidden_to_hidden(h))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1486121c-219c-4643-9454-7eda047ef20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, hidden_size: int, output_size: int, num_layers: int = 1) -> None:\n",
    "        '''A multi-layer RNN model for sequence processing.\n",
    "        \n",
    "        This RNN implementation processes sequences using multiple stacked RNN cells.\n",
    "        Each layer processes the output from the previous layer, with the first layer\n",
    "        processing embedded input tokens and the final layer feeding into an output layer.\n",
    "        \n",
    "        Args:\n",
    "            vocab_size (int): Size of the vocabulary (number of unique tokens)\n",
    "            embedding_dim (int): Dimension of the token embeddings\n",
    "            hidden_size (int): Size of the hidden state in each RNN cell\n",
    "            output_size (int): Size of the output vector\n",
    "            num_layers (int, optional): Number of stacked RNN layers. Defaults to 1.\n",
    "            \n",
    "        Attributes:\n",
    "            embedding (nn.Embedding): Embedding layer that converts token IDs to vectors\n",
    "            rnn_cells (nn.ModuleList): List of RNN cells, one per layer\n",
    "            output_layer (nn.Linear): Final linear transformation to output size\n",
    "        '''\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.register_buffer('vocab_size', torch.tensor(vocab_size))\n",
    "        self.register_buffer('embedding_dim', torch.tensor(embedding_dim))\n",
    "        self.register_buffer('hidden_size', torch.tensor(hidden_size))\n",
    "        self.register_buffer('output_size', torch.tensor(output_size))\n",
    "        self.register_buffer('num_layers', torch.tensor(num_layers))\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn_cells = nn.ModuleList()\n",
    "        self.rnn_cells.append(RNNCell(embedding_dim, hidden_size))\n",
    "        for layer_idx in range(1, num_layers):\n",
    "            self.rnn_cells.append(RNNCell(hidden_size, hidden_size))\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size, bias=False)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        batch_size, seq_len = x.size()\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        hidden_states = [torch.zeros(size=(batch_size, self.hidden_size), device=x.device) for layer_idx in range(self.num_layers)]\n",
    "        for time_step in range(seq_len):\n",
    "            input_to_rnn_cell = x[:, time_step, :]\n",
    "            for layer_idx in range(self.num_layers):\n",
    "                hidden_states[layer_idx] = self.rnn_cells[layer_idx](input_to_rnn_cell, hidden_states[layer_idx])\n",
    "                input_to_rnn_cell = hidden_states[layer_idx]\n",
    "\n",
    "        output = self.output_layer(hidden_states[-1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e83483f6-4e9a-4135-892d-77f0a5c23046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8789bfb770e14118b8356ec021a43607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2c40e18498445788eea01e5e29f558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_folder_path = os.path.join(pp.aclImdb_dataset_folder_path, 'train')\n",
    "dataset = datasets.load_from_disk(dataset_folder_path)\n",
    "\n",
    "train_and_val_datasets = dataset.train_test_split(test_size=0.3)\n",
    "train_dataset = train_and_val_datasets['train']\n",
    "val_dataset = train_and_val_datasets['test']\n",
    "\n",
    "len_train_dataset = len(train_dataset)\n",
    "num_pos_instances_in_train_dataset = len(train_dataset.filter(lambda item: item['label'] == 'pos'))\n",
    "num_neg_instances_in_train_dataset = len_train_dataset - num_pos_instances_in_train_dataset\n",
    "\n",
    "len_val_dataset = len(val_dataset)\n",
    "num_pos_instances_in_val_dataset = len(val_dataset.filter(lambda item: item['label'] == 'pos'))\n",
    "num_neg_instances_in_val_dataset = len_val_dataset - num_pos_instances_in_val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc64152-0838-4873-bcb6-9c990effe819",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_folder_path = os.path.join(pp.word_piece_tokenizer_folder_path, '4096')\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_folder_path)\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2977b7d8-2689-41ea-bb6a-3db13a814612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(4096, 512)\n",
       "  (rnn_cells): ModuleList(\n",
       "    (0): RNNCell(\n",
       "      (input_to_hidden): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (hidden_to_hidden): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=512, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "embedding_dim = 512\n",
    "hidden_size = 512\n",
    "output_size = 1\n",
    "num_layers = 1\n",
    "\n",
    "model = RNN(vocab_size, embedding_dim, hidden_size, output_size, num_layers)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d098f9ac-75c9-4aca-be6d-b80d64e70607",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "train_batch_size = 64\n",
    "val_batch_size = 64\n",
    "num_epochs = 5\n",
    "num_train_batches = math.ceil(len(train_dataset) / train_batch_size)\n",
    "num_val_batches = math.ceil(len(val_dataset) / val_batch_size)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "122129b6-543b-4db9-821b-3dcd35290389",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'neg': 0, 'pos': 1}\n",
    "def collate_fn(batch):\n",
    "    texts = [item['text'] for item in batch]\n",
    "    labels = [[label_map[item['label']]] for item in batch]    \n",
    "    encodings = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "    input_ids = encodings['input_ids']\n",
    "    # attention_mask = encodings['attention_mask']\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    return input_ids, labels\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710faec9-6b9b-4d6a-aef2-02afa2f6e902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e7b0a627f84af985bbfe1ff7ebf2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 average loss: 0.011\n",
      "Epoch 2 average loss: 0.009\n",
      "Epoch 3 average loss: 0.008\n",
      "Epoch 4 average loss: 0.009\n",
      "Epoch 5 average loss: 0.008\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(total=num_epochs * num_train_batches, dynamic_ncols=True)\n",
    "for epoch_idx in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        input_ids, labels = [item.to(device) for item in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_logits = model(input_ids)\n",
    "\n",
    "        loss = criterion(output_logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_description(f'Batch loss: {round(loss.item(), 3)}')\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    avg_loss = epoch_loss / len_train_dataset\n",
    "    print(f'Epoch {epoch_idx + 1} average loss: {round(avg_loss, 3)}')\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acee1839-59ca-4c1d-8d87-5f8b6f42b6dd",
   "metadata": {},
   "source": [
    "model_save_file_path = os.path.join(pp.rnn_models_folder_path, '01.pth')\n",
    "model.save(model.state_dict(), model_save_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72bbe225-6c03-464e-9507-b7a6d5a7fdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_26552\\2825891576.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_file_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(vocab_size, embedding_dim, hidden_size, output_size, num_layers)\n",
    "model_save_file_path = os.path.join(pp.rnn_models_folder_path, '01.pth')\n",
    "model.load_state_dict(torch.load(model_save_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "385db138-ca15-4664-82ff-38fedea0008d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(4096, 512)\n",
       "  (rnn_cells): ModuleList(\n",
       "    (0): RNNCell(\n",
       "      (input_to_hidden): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (hidden_to_hidden): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=512, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17109921-7aed-4574-8c48-0f505ef4ea69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5ffc83f62b46ff94e339ecdeccdb84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7550666928291321\n",
      "Precision: 0.7969143390655518\n",
      "Recall: 0.6798281073570251\n"
     ]
    }
   ],
   "source": [
    "tp = fp = tn = fn = 0\n",
    "progress_bar = tqdm(total=num_val_batches, dynamic_ncols=True)\n",
    "for batch_idx, batch in enumerate(val_dataloader):\n",
    "    input_ids, labels = [item.to(device) for item in batch]\n",
    "\n",
    "    output_logits = model(input_ids)\n",
    "    probs = nn.functional.sigmoid(output_logits)\n",
    "    probs[probs >= 0.5] = 1\n",
    "    probs[probs < 0.5] = 0\n",
    "\n",
    "    tp += ((probs == 1.0) & (labels == 1.0)).sum()\n",
    "    fp += ((probs == 1.0) & (labels == 0.0)).sum()\n",
    "    tn += ((probs == 0.0) & (labels == 0.0)).sum()\n",
    "    fn += ((probs == 0.0) & (labels == 1.0)).sum()\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "precision = (tp) / (tp + fp)\n",
    "recall = (tp) / (tp + fn)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c46431-3c8f-4e33-af1e-53a564dd760d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
